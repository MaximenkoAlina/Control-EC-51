{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Описание дынных. Исходный датасет имеет 10 переменных.9 первых переменных - это независимые. Последняя переменная \"Category\" - зависимая переменная. Переменная \"Category\" состоит из двух типов: 0 и 1, где 0 - это здоровые люди, 1 - заболевшие.\n",
    "Конвертируем наш документ в формат csv с разделителем \"запятая\". \n",
    "Осуществим подготовку данных, импортировав необходимые библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим наш предварительно конвертированный файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "df = pd.read_csv('CR_2.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем данные на экран чтобы убедиться в правильности отображения. Имеем 10 колонок и 615 строк."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ALB</th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>CHE</th>\n",
       "      <th>GGT</th>\n",
       "      <th>PROT</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>m</td>\n",
       "      <td>38.5</td>\n",
       "      <td>52.5</td>\n",
       "      <td>7.7</td>\n",
       "      <td>22.1</td>\n",
       "      <td>6.93</td>\n",
       "      <td>12.1</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>m</td>\n",
       "      <td>38.5</td>\n",
       "      <td>70.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>11.17</td>\n",
       "      <td>15.6</td>\n",
       "      <td>76.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>m</td>\n",
       "      <td>46.9</td>\n",
       "      <td>74.7</td>\n",
       "      <td>36.2</td>\n",
       "      <td>52.6</td>\n",
       "      <td>8.84</td>\n",
       "      <td>33.2</td>\n",
       "      <td>79.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>m</td>\n",
       "      <td>43.2</td>\n",
       "      <td>52.0</td>\n",
       "      <td>30.6</td>\n",
       "      <td>22.6</td>\n",
       "      <td>7.33</td>\n",
       "      <td>33.8</td>\n",
       "      <td>75.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>m</td>\n",
       "      <td>39.2</td>\n",
       "      <td>74.1</td>\n",
       "      <td>32.6</td>\n",
       "      <td>24.8</td>\n",
       "      <td>9.15</td>\n",
       "      <td>29.9</td>\n",
       "      <td>68.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>62</td>\n",
       "      <td>f</td>\n",
       "      <td>32.0</td>\n",
       "      <td>416.6</td>\n",
       "      <td>5.9</td>\n",
       "      <td>110.3</td>\n",
       "      <td>5.57</td>\n",
       "      <td>650.9</td>\n",
       "      <td>68.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>64</td>\n",
       "      <td>f</td>\n",
       "      <td>24.0</td>\n",
       "      <td>102.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>44.4</td>\n",
       "      <td>1.54</td>\n",
       "      <td>35.9</td>\n",
       "      <td>71.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>64</td>\n",
       "      <td>f</td>\n",
       "      <td>29.0</td>\n",
       "      <td>87.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.66</td>\n",
       "      <td>64.2</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>46</td>\n",
       "      <td>f</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>3.56</td>\n",
       "      <td>50.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>59</td>\n",
       "      <td>f</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9.07</td>\n",
       "      <td>34.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>615 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age Sex   ALB    ALP    ALT    AST    CHE    GGT  PROT  Category\n",
       "0     32   m  38.5   52.5    7.7   22.1   6.93   12.1  69.0         0\n",
       "1     32   m  38.5   70.3   18.0   24.7  11.17   15.6  76.5         0\n",
       "2     32   m  46.9   74.7   36.2   52.6   8.84   33.2  79.3         0\n",
       "3     32   m  43.2   52.0   30.6   22.6   7.33   33.8  75.7         0\n",
       "4     32   m  39.2   74.1   32.6   24.8   9.15   29.9  68.7         0\n",
       "..   ...  ..   ...    ...    ...    ...    ...    ...   ...       ...\n",
       "610   62   f  32.0  416.6    5.9  110.3   5.57  650.9  68.5         1\n",
       "611   64   f  24.0  102.8    2.9   44.4   1.54   35.9  71.3         1\n",
       "612   64   f  29.0   87.3    3.5   99.0   1.66   64.2  82.0         1\n",
       "613   46   f  33.0    NaN   39.0   62.0   3.56   50.0  71.0         1\n",
       "614   59   f  36.0    NaN  100.0   80.0   9.07   34.0  68.0         1\n",
       "\n",
       "[615 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для определения пропущенных значений в переменных выведем общее количество и процент пропусков по переменным. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALP</th>\n",
       "      <td>18</td>\n",
       "      <td>0.029268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROT</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALT</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALB</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GGT</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AST</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Total   Percent\n",
       "ALP          18  0.029268\n",
       "PROT          1  0.001626\n",
       "ALT           1  0.001626\n",
       "ALB           1  0.001626\n",
       "Category      0  0.000000\n",
       "GGT           0  0.000000\n",
       "CHE           0  0.000000\n",
       "AST           0  0.000000\n",
       "Sex           0  0.000000\n",
       "Age           0  0.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cheking Missing data\n",
    "total = df.isnull().sum().sort_values(ascending=False)\n",
    "percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, есть пропущенные значения. Проведем поиск и подстановку пропущенных значений, при чем имеем картину, что пропуски\n",
    "присутствуют только в числовых значений. Соответственно произведем поиск и подстановку только числовых значений. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Missing data (numeric)\n",
    "def fill_missing_num(x):\n",
    "    num_var = list(x._get_numeric_data().columns)\n",
    "    for col_names in num_var:        \n",
    "        prep_med = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "        prep_med.fit(x[num_var])\n",
    "        x[num_var] = prep_med.transform(x[num_var])\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполним пропуски полученными значениями. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling NA \n",
    "from sklearn.impute import SimpleImputer\n",
    "df = fill_missing_num(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заново выведем общее количество и процент пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROT</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GGT</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AST</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALT</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALP</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALB</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Total  Percent\n",
       "Category      0      0.0\n",
       "PROT          0      0.0\n",
       "GGT           0      0.0\n",
       "CHE           0      0.0\n",
       "AST           0      0.0\n",
       "ALT           0      0.0\n",
       "ALP           0      0.0\n",
       "ALB           0      0.0\n",
       "Sex           0      0.0\n",
       "Age           0      0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cheking Missing data\n",
    "total = df.isnull().sum().sort_values(ascending=False)\n",
    "percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем статистику по числовым значениям. Как и следовало ожидать - пропущенных значений нет. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>ALB</th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>CHE</th>\n",
       "      <th>GGT</th>\n",
       "      <th>PROT</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>47.408130</td>\n",
       "      <td>41.620195</td>\n",
       "      <td>68.283920</td>\n",
       "      <td>28.450814</td>\n",
       "      <td>34.786341</td>\n",
       "      <td>8.196634</td>\n",
       "      <td>39.533171</td>\n",
       "      <td>72.044137</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.055105</td>\n",
       "      <td>5.775920</td>\n",
       "      <td>25.643955</td>\n",
       "      <td>25.448940</td>\n",
       "      <td>33.090690</td>\n",
       "      <td>2.205657</td>\n",
       "      <td>54.661071</td>\n",
       "      <td>5.398234</td>\n",
       "      <td>0.340211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>11.300000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>1.420000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>44.800000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>38.800000</td>\n",
       "      <td>52.950000</td>\n",
       "      <td>16.400000</td>\n",
       "      <td>21.600000</td>\n",
       "      <td>6.935000</td>\n",
       "      <td>15.700000</td>\n",
       "      <td>69.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>41.900000</td>\n",
       "      <td>66.700000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>25.900000</td>\n",
       "      <td>8.260000</td>\n",
       "      <td>23.300000</td>\n",
       "      <td>72.200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>45.200000</td>\n",
       "      <td>79.300000</td>\n",
       "      <td>33.050000</td>\n",
       "      <td>32.900000</td>\n",
       "      <td>9.590000</td>\n",
       "      <td>40.200000</td>\n",
       "      <td>75.400000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>82.200000</td>\n",
       "      <td>416.600000</td>\n",
       "      <td>325.300000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>16.410000</td>\n",
       "      <td>650.900000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age         ALB         ALP         ALT         AST         CHE  \\\n",
       "count  615.000000  615.000000  615.000000  615.000000  615.000000  615.000000   \n",
       "mean    47.408130   41.620195   68.283920   28.450814   34.786341    8.196634   \n",
       "std     10.055105    5.775920   25.643955   25.448940   33.090690    2.205657   \n",
       "min     19.000000   14.900000   11.300000    0.900000   10.600000    1.420000   \n",
       "25%     39.000000   38.800000   52.950000   16.400000   21.600000    6.935000   \n",
       "50%     47.000000   41.900000   66.700000   23.000000   25.900000    8.260000   \n",
       "75%     54.000000   45.200000   79.300000   33.050000   32.900000    9.590000   \n",
       "max     77.000000   82.200000  416.600000  325.300000  324.000000   16.410000   \n",
       "\n",
       "              GGT        PROT    Category  \n",
       "count  615.000000  615.000000  615.000000  \n",
       "mean    39.533171   72.044137    0.133333  \n",
       "std     54.661071    5.398234    0.340211  \n",
       "min      4.500000   44.800000    0.000000  \n",
       "25%     15.700000   69.300000    0.000000  \n",
       "50%     23.300000   72.200000    0.000000  \n",
       "75%     40.200000   75.400000    0.000000  \n",
       "max    650.900000   90.000000    1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осуществим работы с выбросами в числовых переменных: для этого запишем функцию для поиска и замены данных, выходящих за \n",
    "пределы 3 сигма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Outliers\n",
    "def outliers(df):\n",
    "    num_var = list(df._get_numeric_data().columns)\n",
    "    for col_names in num_var:\n",
    "        df[col_names] = df[col_names].apply(lambda y: df[col_names].mean()-3*df[col_names].std() \n",
    "                            if y < df[col_names].mean()-3*df[col_names].std() else y)\n",
    "        df[col_names] = df[col_names].apply(lambda y: df[col_names].mean()+3*df[col_names].std() \n",
    "                            if y > df[col_names].mean()+3*df[col_names].std() else y)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишем в наш датафрейм уже очищенные от выбросов переменные и повторно выведем статистику. \n",
    "В результате выполнения очистки можно наблюдать, что показатели максимального, минимального,среднего значений, \n",
    "а также стандартного отклонения изменились. Значит у нас имелись выбросы, но из-за проведенных выше работ с выбросами, \n",
    "мы от них избавились, поэтому теперь наши данные соответствуют нормальному распределению,что говорит об отсутствии выбросов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>ALB</th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>CHE</th>\n",
       "      <th>GGT</th>\n",
       "      <th>PROT</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>47.408130</td>\n",
       "      <td>41.619142</td>\n",
       "      <td>67.666273</td>\n",
       "      <td>27.375654</td>\n",
       "      <td>33.139378</td>\n",
       "      <td>8.191132</td>\n",
       "      <td>36.816201</td>\n",
       "      <td>72.117821</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.055105</td>\n",
       "      <td>5.363302</td>\n",
       "      <td>20.790903</td>\n",
       "      <td>18.293360</td>\n",
       "      <td>23.652140</td>\n",
       "      <td>2.184622</td>\n",
       "      <td>37.237116</td>\n",
       "      <td>5.085763</td>\n",
       "      <td>0.340211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>24.292435</td>\n",
       "      <td>11.300000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>1.579662</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>55.849434</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>38.800000</td>\n",
       "      <td>52.950000</td>\n",
       "      <td>16.400000</td>\n",
       "      <td>21.600000</td>\n",
       "      <td>6.935000</td>\n",
       "      <td>15.700000</td>\n",
       "      <td>69.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>41.900000</td>\n",
       "      <td>66.700000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>25.900000</td>\n",
       "      <td>8.260000</td>\n",
       "      <td>23.300000</td>\n",
       "      <td>72.200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>45.200000</td>\n",
       "      <td>79.300000</td>\n",
       "      <td>33.050000</td>\n",
       "      <td>32.900000</td>\n",
       "      <td>9.590000</td>\n",
       "      <td>40.200000</td>\n",
       "      <td>75.400000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>58.479990</td>\n",
       "      <td>145.215784</td>\n",
       "      <td>104.797633</td>\n",
       "      <td>134.058412</td>\n",
       "      <td>14.809541</td>\n",
       "      <td>203.516384</td>\n",
       "      <td>87.420364</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age         ALB         ALP         ALT         AST         CHE  \\\n",
       "count  615.000000  615.000000  615.000000  615.000000  615.000000  615.000000   \n",
       "mean    47.408130   41.619142   67.666273   27.375654   33.139378    8.191132   \n",
       "std     10.055105    5.363302   20.790903   18.293360   23.652140    2.184622   \n",
       "min     19.000000   24.292435   11.300000    0.900000   10.600000    1.579662   \n",
       "25%     39.000000   38.800000   52.950000   16.400000   21.600000    6.935000   \n",
       "50%     47.000000   41.900000   66.700000   23.000000   25.900000    8.260000   \n",
       "75%     54.000000   45.200000   79.300000   33.050000   32.900000    9.590000   \n",
       "max     77.000000   58.479990  145.215784  104.797633  134.058412   14.809541   \n",
       "\n",
       "              GGT        PROT    Category  \n",
       "count  615.000000  615.000000  615.000000  \n",
       "mean    36.816201   72.117821    0.133333  \n",
       "std     37.237116    5.085763    0.340211  \n",
       "min      4.500000   55.849434    0.000000  \n",
       "25%     15.700000   69.300000    0.000000  \n",
       "50%     23.300000   72.200000    0.000000  \n",
       "75%     40.200000   75.400000    0.000000  \n",
       "max    203.516384   87.420364    1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outliers\n",
    "df = outliers(df)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем проверку типов данных по переменным и выявим соответствие."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age         float64\n",
       "Sex          object\n",
       "ALB         float64\n",
       "ALP         float64\n",
       "ALT         float64\n",
       "AST         float64\n",
       "CHE         float64\n",
       "GGT         float64\n",
       "PROT        float64\n",
       "Category    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы получили подготовленный набор данных, который можно далее использовать для моделирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашем датасете присутствуют качественные переменные - пол. Ее необходимо закодировать с помощью функции.\n",
    "Запишем список нечисловых переменных и проведем кодирование качественных переменных. Результат запишем обратно в базу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Encoding\n",
    "def encoding_char(x):\n",
    "    char_var = list(set(x.columns) - set(x._get_numeric_data().columns))\n",
    "    for col_names in char_var:\n",
    "        f = pd.factorize(x[col_names])\n",
    "        x[col_names] = pd.factorize(x[col_names])[0]\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical data\n",
    "df = encoding_char(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как будут выглядеть наши закодированные данные. Теперь все переменные в ней являются числовыми. \n",
    "С ними можно теперь работать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ALB</th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>CHE</th>\n",
       "      <th>GGT</th>\n",
       "      <th>PROT</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.500000</td>\n",
       "      <td>52.500000</td>\n",
       "      <td>7.7</td>\n",
       "      <td>22.1</td>\n",
       "      <td>6.930000</td>\n",
       "      <td>12.100000</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.500000</td>\n",
       "      <td>70.300000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>11.170000</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>76.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>46.900000</td>\n",
       "      <td>74.700000</td>\n",
       "      <td>36.2</td>\n",
       "      <td>52.6</td>\n",
       "      <td>8.840000</td>\n",
       "      <td>33.200000</td>\n",
       "      <td>79.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>43.200000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>30.6</td>\n",
       "      <td>22.6</td>\n",
       "      <td>7.330000</td>\n",
       "      <td>33.800000</td>\n",
       "      <td>75.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.200000</td>\n",
       "      <td>74.100000</td>\n",
       "      <td>32.6</td>\n",
       "      <td>24.8</td>\n",
       "      <td>9.150000</td>\n",
       "      <td>29.900000</td>\n",
       "      <td>68.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>62.0</td>\n",
       "      <td>1</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>145.215784</td>\n",
       "      <td>5.9</td>\n",
       "      <td>110.3</td>\n",
       "      <td>5.570000</td>\n",
       "      <td>203.516384</td>\n",
       "      <td>68.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24.292435</td>\n",
       "      <td>102.800000</td>\n",
       "      <td>2.9</td>\n",
       "      <td>44.4</td>\n",
       "      <td>1.579662</td>\n",
       "      <td>35.900000</td>\n",
       "      <td>71.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>87.300000</td>\n",
       "      <td>3.5</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>64.200000</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>46.0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>68.283920</td>\n",
       "      <td>39.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>3.560000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>59.0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>68.283920</td>\n",
       "      <td>100.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9.070000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>615 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Sex        ALB         ALP    ALT    AST        CHE         GGT  \\\n",
       "0    32.0    0  38.500000   52.500000    7.7   22.1   6.930000   12.100000   \n",
       "1    32.0    0  38.500000   70.300000   18.0   24.7  11.170000   15.600000   \n",
       "2    32.0    0  46.900000   74.700000   36.2   52.6   8.840000   33.200000   \n",
       "3    32.0    0  43.200000   52.000000   30.6   22.6   7.330000   33.800000   \n",
       "4    32.0    0  39.200000   74.100000   32.6   24.8   9.150000   29.900000   \n",
       "..    ...  ...        ...         ...    ...    ...        ...         ...   \n",
       "610  62.0    1  32.000000  145.215784    5.9  110.3   5.570000  203.516384   \n",
       "611  64.0    1  24.292435  102.800000    2.9   44.4   1.579662   35.900000   \n",
       "612  64.0    1  29.000000   87.300000    3.5   99.0   1.660000   64.200000   \n",
       "613  46.0    1  33.000000   68.283920   39.0   62.0   3.560000   50.000000   \n",
       "614  59.0    1  36.000000   68.283920  100.0   80.0   9.070000   34.000000   \n",
       "\n",
       "     PROT  Category  \n",
       "0    69.0       0.0  \n",
       "1    76.5       0.0  \n",
       "2    79.3       0.0  \n",
       "3    75.7       0.0  \n",
       "4    68.7       0.0  \n",
       "..    ...       ...  \n",
       "610  68.5       1.0  \n",
       "611  71.3       1.0  \n",
       "612  82.0       1.0  \n",
       "613  71.0       1.0  \n",
       "614  68.0       1.0  \n",
       "\n",
       "[615 rows x 10 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим наш датасет на обучающую и тестовую вывборку по пропорции 20% на 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем шкалирование данных. Из библиотеки импортируем класс StandardScaler и рассчитаем и запишем в переменную необходимые \n",
    "параметры шкалирования, посчитанные на основе обучающей выборки. Затем с использованием жтих параметров шкалируем обучающую и \n",
    "тестовую выборкую. Эндогенная переменная в шкалировании не нуждается. Она должна быть дискретного типа 0;1. Что у нас и есть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler().fit(X_train)\n",
    "X_train = sc_X.transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строим базовую модель. Для жтого из библиотеки statsmodels с помощью ф-и Logit посмотрим отчет по модели. Видим, что из все \n",
    "переменных значимыми будут переменные: Х5, Х6,Х8; т.к. их значения Р не превышают 1%. Остальные переменные не будем использовать\n",
    "для построения классификаторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.319196\n",
      "         Iterations 8\n",
      "                         Results: Logit\n",
      "=================================================================\n",
      "Model:              Logit            Pseudo R-squared: 0.198     \n",
      "Dependent Variable: y                AIC:              332.0884  \n",
      "Date:               2020-11-23 12:29 BIC:              369.8747  \n",
      "No. Observations:   492              Log-Likelihood:   -157.04   \n",
      "Df Model:           8                LL-Null:          -195.80   \n",
      "Df Residuals:       483              LLR p-value:      1.5480e-13\n",
      "Converged:          1.0000           Scale:            1.0000    \n",
      "No. Iterations:     8.0000                                       \n",
      "--------------------------------------------------------------------\n",
      "       Coef.     Std.Err.       z       P>|z|      [0.025     0.975]\n",
      "--------------------------------------------------------------------\n",
      "x1    -0.1793      0.1523    -1.1773    0.2391    -0.4779     0.1192\n",
      "x2     0.0076      0.1572     0.0482    0.9616    -0.3006     0.3157\n",
      "x3    -0.4735      0.2086    -2.2699    0.0232    -0.8824    -0.0646\n",
      "x4    -0.2855      0.1845    -1.5472    0.1218    -0.6471     0.0762\n",
      "x5    -1.7863      0.2590    -6.8976    0.0000    -2.2939    -1.2787\n",
      "x6     5.6411      0.5079    11.1073    0.0000     4.6457     6.6365\n",
      "x7    -0.3568      0.1867    -1.9106    0.0561    -0.7227     0.0092\n",
      "x8     0.9985      0.2320     4.3036    0.0000     0.5438     1.4532\n",
      "x9     0.2999      0.1959     1.5309    0.1258    -0.0840     0.6838\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Baseline model\n",
    "import statsmodels.api as sm\n",
    "lr = sm.Logit(y_train, X_train).fit()\n",
    "print(lr.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем оставленные нами значения Х5, Х6,Х8 для построения классификаторов. Преобразуем обучающую и тестовую выборку, \n",
    "оставив только значимые переменные. При чем проведем эксперимент: какая пара значений имеет лучшее качество."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оставим значения Х5, Х6. Имеем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p-value < 1% Features\n",
    "X_train1 = X_train[:,[4,5]]\n",
    "X_test1 = X_test[:,[4,5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель логистической регрессии с использованием библиотеки sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Logistic Regression to the Training set (2 variables)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(random_state = 13).fit(X_train1, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем прогноз на тестовой выборке и оценим качество этой модели. Видим, что уровень качества базовой модели очень высок\n",
    "и превышает 95%. Значит 95% объектов у нас распознаны верно. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.959349593495935"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = lr.predict(X_test1)\n",
    "lr.score(X_test1,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оставим значения Х6, Х8. Имеем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p-value < 1% Features\n",
    "X_train2 = X_train[:,[5,7]]\n",
    "X_test2 = X_test[:,[5,7]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель логистической регрессии с использованием библиотеки sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Logistic Regression to the Training set (2 variables)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(random_state = 13).fit(X_train2, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем прогноз на тестовой выборке и оценим качество этой модели. Видим, что уровень качества базовой модели очень высок\n",
    "и превышает 94%. Значит 94% объектов у нас распознаны верно. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.943089430894309"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = lr.predict(X_test2)\n",
    "lr.score(X_test2,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оставим значения Х5, Х8. Имеем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p-value < 1% Features\n",
    "X_train3 = X_train[:,[4,7]]\n",
    "X_test3 = X_test[:,[4,7]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель логистической регрессии с использованием библиотеки sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Logistic Regression to the Training set (2 variables)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(random_state = 13).fit(X_train3, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем прогноз на тестовой выборке и оценим качество этой модели. Видим, что уровень качества базовой модели очень высок\n",
    "и превышает 89%. Значит 89% объектов у нас распознаны верно. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8943089430894309"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = lr.predict(X_test3)\n",
    "lr.score(X_test3,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В соответствии с качеством модели делаем вывод, что стоит оставить переменные Х5 и Х6, т.к. качество можели составляет 95.9%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на таблицу сопряженности. Видим, что 5 положительных случаев ложно определены как отрицательные и 0 отрицательных\n",
    "случаев ложно определены как положительный."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[108   0]\n",
      " [  5  10]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на область значений нашей функции для визуализации разделяющей прямой. Это нужно для того, чтобы понимать как объекты\n",
    "одного типа отделяются от объектов другого типа. По каждой переменной создадим множество точек в диапазоне изменения пременных \n",
    "от минимума до максимума с шагом в 0,01. Множество зеленых точек - прогноз класса 1, множество красных точек - прогноз класса 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2-D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2-D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEWCAYAAABv+EDhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5gcdZ3v8fd3ZkIHzBBiIJMEiHEOAVlBwm7ggLgnEJVFBRWvYcFH9+jJcfd4C+6DYsQjPEbPcVdAH6/hsl7IMbpqVO4CJkA8QQicgGIYZBsSQpIJhAAZEzrJ9Pf8UdVJT6cv1dfq7vq8nmeezFRXV327JvP7Vn1/v/qVuTsiIpI8PXEHICIi8VACEBFJKCUAEZGEUgIQEUkoJQARkYRSAhARSSglAKmbmX3XzC6r4X0zzGzEzHqbEVe7MrNbzeyDTdr22Wb2y2Zsu5XM7Bdmdk7ccXQ7030AyWJmTwEfcfc7O3XfZvYh4DpgF5AFngQWuftN9cbY6cxsDfAxYBPwp7yXXgHsBHJ/8G9x93ur3PZTNOH/jpl9ETjG3S/KW3Yq8B13/5tG7kvG0hWAdKrV7j4BOAz4NrDMzA5r9E466erEzE4BJrr7fe6+wd0n5L7CVU7KW1ZV499q7n4/cKiZzYk7lm6mBCAAmFnKzK42s03h19Vmlsp7/RIz2xy+9hEzczM7Jnzt+2b2pfD7w83sJjN7wcyeN7N7zazHzH4EzABuDMs+l5jZzHA7feF7X2lm/xbuY3uUUoa7Z4EfEZzhzsr7LP9qZhvMbDgsUR1cxWf5jpndYmZ/Ac4ys+lm9nMze9bMnjSzT+Rt61QzW2NmL4X7ujJcPt7MbjCzbeGxeMDMBsLXVprZR8Lve8zs82a23sy2mtkPzWxi+Fru+Hww/CzPmdmiMofjLcDdEX/XRY9PNb+/Itst+t7wtaLHMCzzfA54f7jdh/M2uRJ4W6XPI7VTApCcRcBpwGzgJOBU4POw74/0YuBNwDHA3DLb+TSwETgCGCD443Z3/wCwATgvPAP9apH3/gg4BHgtMAW4qlLQ4Rn6PwB7gPXh4v8NHBt+lmOAI4EvVPFZ/h5YDPQD/xe4EXg43M4bgU+Z2d+F634d+Lq7Hwr8J+Cn4fIPAhOBo4HJwEcJSlaFPhR+nQUMAhOAbxas8wbguHDfXzCz40scjhOBoRKv5St5fKjv91f0vWESKHoM3f024MvAT8LtnpS3vXUE/xelSZQAJOdC4Ap33+ruzwKXAx8IX3sf8G/u/qi77wxfK2UPMA14lbvvcfd7PUJHk5lNIziD/ai7bw/fW+5s9jQzewF4GfhX4CJ332pmBvw3YKG7P+/uOwgamPlVfJZfufvvwquLE4Ej3P0Kd9/t7mngmrzt7QGOMbPD3X3E3e/LWz6ZoLY96u4PuvtLRfZ1IXClu6fdfQS4FJifuyoKXe7uu9z9YYJGtFSjeBiwo8wxI8Lxqen3V+G9p1D+GJayI/xM0iRKAJIznf1n0ITfT8977em81/K/L/QvwBPAb8wsbWafjbj/o4Hn3X17xPXvc/fDgEnAr4G/DZcfQXAV8WBYingBuC1cDtE+S/6yVwHTc9sKt/c5gjNcgA8TnE0/FpZ5zg2X/wi4naBvYpOZfdXMxhXZV7Hj3pe3fYAted/vJLhKKGY7wVVLOZWOT62/v3LvrXQMS+kHXqhi/1KlvsqrSEJsIvhDfTT8eUa4DGAzcFTeukeX2kh4Rvlp4NNm9lpghZk94O53sX8ESjFPA680s8PcPfIfvbuPmNk/Af9hZtcTnCHvAl7r7s8UeUuUz5If59PAk+4+q8T+/wxcEJY53gX8zMwmu/tfCK4uLjezmcAtBOWZ6wo2kTvuOTOAvcBwQZxRPEKQjMp5jjLHp47fX8n3UuEYltnu8QS/T2kSXQEk07iwkzL31Qf8GPi8mR1hZocT1IRvCNf/KfAPZna8mR3C/nrxAczsXDM7Jiw1vASMhl8QNGqDxd7n7puBW4Fvm9kkMxtnZv8lyodx923AtcAXwrLNNcBVZjYljOnIvJp95M8Suh94ycw+Y2YHm1mvmZ1gwYgbzOwiMzsi3G8ucY2a2VlmdmLYR/ESQXlktMj2fwwsNLNXm9kE9tfD90b57AVuoXz/DJWOT62/vwrvLXsMw+3OzHUY55lL8H9CmkQJIJluITgLzH19EfgSsIbgLPIPwEPhMtz9VuAbwAqCS/zV4XYyRbY9C7gTGAnX+7a7rwxf+wpBknnBzP65yHs/QNBQPgZsBT5VxWe6Gnirmb0O+EwY531m9lIYz3E1fBbcfRQ4j6DD9EmCM+hrCTp4Ac4BHjWzEYIO4fnu/jIwFfgZQUO4jmB0zg0c6HqCctE94fZfBj5exefOj/Uh4EUz+88VVi15fKjv91f0vRGO4b+H/24zs4dg35DWv4TDQaVJdCOYVC0chfJHIFXjmWrb6KbPAsGdwMA/ufs7446lHmb2c+A6d78l7li6mRKARGJm5wM3E4y3/wGQ7dRGpps+i0g9VAKSqP478CzwHwR13X+MN5y6dNNnEamZrgBERBJKVwAiIgnVUfcBjOsf5+MPHx93GCIiHWXkqZHn3P2IwuUdlQDGHz6eOV/U5IAiItVY+aGV64stjzUBWDC/+A6Cjri97q7WXUSkRdrhCuAsd38u7iBERJJGncAiIgkV9xWAE8wc6MD33H1J4QpmtgBYAJCanCp8WUSkLhN6JzB/xnymHTyNng4+J86SZfOuzSzbsIyR0ZFI74k7AZzh7pvCSanuMLPH3P2e/BXCpLAEoP/V/bppQUQaav6M+Zxw1Amk+lME89h1Jndn8o7JzGc+1z55baT3xJru3H1T+O9WYDnBU6hERFpm2sHTOr7xBzAzUv0pph08LfJ7YksAZvYKM+vPfQ+cTTApl4hIy/TQ0/GNf46ZVVXGirMENAAsDw98H/B/wueDiohIC8R2BRA+A/Wk8Ou17r44rlhEROJ07133cs5p53D2KWez5OsHjIXB3fnSpV/i7FPO5u1z386jDz9aZCvV69wubxGRLjA6OsoVn72Ca5Zdw02/u4mbl9/ME0NPjFnnnjvvYX16PbfffztXfO0KLr/k8obsWwlARKQK/T+7kcGT53HslOMZPHke/T+7sa7tPfLQI8yYOYOjZx7NQQcdxFvf+VbuuvWuMevcddtdvOP978DMmD1nNi+9+BJbt2yta7+gBCAiEln/z25k6sWXMW7jJsydcRs3MfXiy+pKAsObh5l25P6RO1OnT2V48/CB60wvWGfL2HVqoQQgIhLREYuvomfXy2OW9ex6mSMWX1X7Rovc3XTAqKQo69RACUBEJKK+ZzZXtTyKgekDbM57/5ZNW5gydcqB62wqWGdg7Dq1UAIQEYlo75HFb7IqtTyKE08+kfVPrmfj+o3s3r2bW355C/POmTdmnXl/N49f/eRXuDtr16yl/9D+A5JELeKeCkJEpGM8u2ghUy++bEwZKHvweJ5dtLDmbfb19XHZVy7jw+/7MNlslndf8G5mvWYWy76/DID5H5rP3DfP5Z477+HsU89m/MHj+fI3vlz3ZwElABGRyHa85zwg6Avoe2Yze4+cxrOLFu5bXqu5b57L3DfPHbNs/ofm7/vezPjCV79Q1z6KUQIQEanCjvecV3eD3y7UByAiklBKACIiCaUEICKSUEoAIiIJpQQgIpJQSgAiIjH73Cc+x+uPfz3n/W3x0UWaDlpEpEudP/98rll2TcnXNR20iEgbuPHxG5n3g3kc/63jmfeDedz4eH3TQQOc8vpTmDhpYsnXmzUdtG4Ek7oNjwyT3p4mM5oh1ZticNIgAxMG4g6rK+jYtpcbH7+Ry1Zcxst7g6kgNo1s4rIVlwFw3rHNuzms1HTQ9c4HpCsAqcvwyDBD24bIjGYAyIxmGNo2xPBI/XOVJ52Obfu5avVV+xr/nJf3vsxVq+uYDjoKTQct7Si9PU3Ws2OWZT1Lens6poi6h45t+9k8Unza51LLG0XTQUtbyp2dRl0u0enYtp9pE4pP+1xqeaN07XTQZtYLrAGecfdz445HqpPqTRVtkFK9qRii6S46tu1n4ekLx/QBAIzvG8/C02ufDhrg4gUX88DvHmD789uZ+7q5fPySj7N3716g+6eD/iSwDjg07kCkeoOTBhnaNjSmVNFjPQxOGowxqu6gY9t+ch29V62+is0jm5k2YRoLT19YdwfwlUuuLPt6V04HbWZHAW8DFgMXxxmL1CY3IkUjVRpPx7Y9nXfseU0d8dNKcV8BXA1cAvTHHIfUYWDCgBqlJtGxlWaKrRPYzM4Ftrr7gxXWW2Bma8xszZ4de1oUnYgkRZYs7kXGWXYgdydLtvKKoThHAZ0BvN3MngKWAfPM7IbCldx9ibvPcfc54/rHtTpGEelym3dtJrMj0/FJwN3J7MiweVf0IamxlYDc/VLgUgAzOxP4Z3e/KK54RCSZlm1YxnzmM+3gafR08Mj4LFk279rMsg3LIr8n7j4AEZFYjYyOcO2T18YdRizaIgG4+0pgZcxhiIgkSude74iISF2UAEREEkoJQEQkoZQAREQSSglARCShlABERBJKCUBEJKGUAEREEkoJQEQkoZQAREQSSglARCSh2mIuIGlfwyPDeiKVSJdSApCShkeGxzyTNjOaYWjbEICSgEgXUAlISkpvT495IDlA1rOkt6djikhEGklXAFJSZjRT1XJpDJXdpFV0BSAlpXpTVS2X+uXKbrkkmyu7DY8MxxyZdCMlAClpcNIgPTb2v0iP9TA4aTCmiLqfym7SSioBSUm5soPKEa2jspu0khKAlDUwYUANfgulelNFG3uV3aQZVAISaSMqu0kr6QpApI2o7CatpAQg0mZUdpNWia0EZGbjzex+M3vYzB41s8vjikVEJInivALIAPPcfcTMxgGrzOxWd78vxphERBIjtgTg7g6MhD+OC788rnhERJIm1lFAZtZrZmuBrcAd7v77IussMLM1ZrZmz449rQ9SRKRLxZoA3H3U3WcDRwGnmtkJRdZZ4u5z3H3OuP5xrQ9SRKRLtcV9AO7+ArASOCfmUEREEiPOUUBHmNlh4fcHA28CHosrHhGRpIlzFNA04Adm1kuQiH7q7jfFGI+ISKLEOQroEeDkuPYvIpJ0bdEHICIiracEICKSUEoAIiIJpQQgIpJQSgAiIgmlBCAiklBKACIiCaUEICKSUEoAIiIJpQQgIpJQSgAiIgmlBCAiklBxzgYqItJxhkeGSW9PkxnNkOpNMThpkIEJA3GHVRMlABGRiIZHhhnaNkTWswBkRjMMbRsC6MgkoBKQiEhE6e3pfY1/TtazpLenY4qoPkoAIiIRZUYzVS1vd0oAIiIRpXpTVS1vd0oAIiIRDU4apMfGNps91sPgpMGYIqqPOoFFRCLKdfRqFJCISAINTBjo2Aa/kEpAIiIJpQQgIpJQsSUAMzvazFaY2Toze9TMPhlXLCIiSRRnH8Be4NPu/pCZ9QMPmtkd7v6nGGMSEUmM2BKAu28GNoff7zCzdcCRgBKAiLRMN83tU622GAVkZjOBk4HfF3ltAbAAIDW5M2+2EJH21G1z+1Qr9k5gM5sA/Bz4lLu/VPi6uy9x9znuPmdc/7jWBygiXavb5vapVqwJwMzGETT+S939F3HGIiLJ021z+1QrzlFABlwHrHP3K+OKQ0SSq9vm9qlWyQRgZjOavO8zgA8A88xsbfj11ibvU0Rkn26b26da5TqBfwn8dbN27O6rAGvW9kVEKum2uX2qVS4BqHEWka5X7dw+7Txs9O4nV1a1frkEcKSZfaPUi+7+iar2JCLS4eIcNrp2y1oAXtz1Qtn1snefecAyY2XRdcslgF3Ag9FCExHpfuWGjTYiAdz91N3BN+4HvNYb7nbibtj++zPr3heUTwDb3P0HDdmLiEgXqHfYaKUSzdz1QeV9xVNnVhNWzcolgN0tiUBEpEOkelNFG/v8YaOVGvns1w8Lvpk9u5Gh1aRcAphvZhPd/UUAMzsLeCewHvimuytBiEhirN2y9oAhowA4ZPZm9jX8E1+uUKKJv93fp1wC+AlwPvCimc0G/h34CnAS8G3gI80PT0SkdcrV4CGow1tufKTBjEyKxelBLtzaHqOAqlUuARzs7pvC7y8Crnf3r5lZD7C2+aGJiDRetDq8seKpuS2JJ05R7wOYB1wK4O7ZcBoHEZG2s3bL2spDJduoDh+ncgngt2b2U4I5+ycBvwUws2nAyy2ITURkjLVb1jKye4TR0b1l18su7oM3vKH0Cslu9/cplwA+BbwfmAa8wd33hMtnAa9sdmAikgyFd9ZmRjMYVrIOPzE8/Szb0Vqm7Zf9SiYAd3dgGYCZzQ6f2fs+4Eng6taEJyLd5u6n7t7XuO9r4sOicmY0Aw6vec750/cqnMVL3UomADM7FpgPXABsIxgVZO5+VotiE5EOFXUs/MyP7mL9+IJx9QY7+1PwhtObFJ3klCsBPQbcC5zn7k8AmNnClkQlIm1r1YZVAGXr8L1Z2HPvmaU3EtbgN6RWFn15QyoZD2SJW7kE8G6CK4AVZnYbQTlIo39EEqDcGXxvFiaEt4HWOyfNjEzqwCuAcLk0X7k+gOXAcjN7BcEdwAuBATP7DrDc3X/TohhFpMEqlWgmvgzbv9b8Gvzi9CALjhtiZ+/+CdYOGe1hcToZD2SJW7krAADc/S/AUmCpmb0SeC/wWUAJQKRNRRoLX2Ta4DFa0P+au4N20WCaDalMx99Z22kqJoB87v488L3wS0RismrDqoo1+F4q1OHbxIVbB9Tgx6SqBCAirRGlRAONmxdekkkJQCQmFYdKLg7/PDUWXppECUCkCaI8vm/u+goTjqndlyZTAhCpwaoNqxjNjpadNhhg7tPJmFVSOlOsCcDMrgfOBba6+wlxxiJSSNMGS7eL+wrg+8A3gR/GHIckUKShkov7YMKExE8bLN0p1gTg7veY2cw4Y2i2wpkOBycNMjAh2pC3et6bdFFq8BDOSVOucVcdXrpY3FcAFZnZAmABQGpyZ90ePjwyzNC2IbIeFIQzoxmGtg0BVGzI63lvUkR5fF/FsfA6sZcEa/sE4O5LgCUA/a/uL/6X3qbS29P7GvCcrGdJb09XbMTreW+3yJ82uBTV4UVq1/YJoJNlRovPaFhqeb3v7cSSUdRpgwHV4UUaTAmgiXJPNyq2vNHvbceSUeQ6fLk5adTmizRN3MNAfwycCRxuZhuB/+nu18UZUyMNThoc0ygD9FgPg5Mqz3RY7XvjKhmVq8PnxsJP3K0pC0TaUdyjgC6Ic//Nlmt4aynLVPveespN5USZk2b2sLHiqTPr2o+ItJ5KQE02MGGg5jPwat5bT7kpch2+nhr88DCk05DJQCoFg4Mw0N79EyLdTgmgSxQrGQHsHt0daergpg6VHB6GoSHIhrFlMsHPoCQgEiMlgA6XX4MvNmBy4ssOBI1/bHX4dHp/45+TzQbLlQBEYqME0AGizEmz4obmP76vZpkS/RCllotISygBtIm66/Bt2vYDQc2/WGOf6qw7u0W6jRJAk63asAqgbA0ewknHyp3Bd/J4+MHBsX0AAD09wXIRiY0SQAM05PF97XwGX69cnV+jgETaihJABJVG0YAe31fRwIAafJE2owQQqjTxWEfX4Lud7jGILmnHKmmft0qJSACV6vCaNrhOjfgjq3UbuscguqQdq6R93hp0TQJoSB1eqteIP7Ji21i3Dl58EY49tvx7dY9BdEk7Vkn7vDXoqAQwkhkp2dD3ZmHPV/T4vpZrxB9ZsW0AbNoEEyfuX6fY1YHuMYguaccqaZ+3Bh2VAP5mxwTW3D2n9Aqqw7deI/7Iyq375z8HyaHUFYbuMYguaccqaZ+3Bj1xByAdrtQfUzV/ZOXW3bu39BUGBFcDPQX/jXWPQXFJO1ZJ+7w16KgrAGkDhZ21kyfDli313eQ1OBjU/KuRO7PTPQbRJe1YJe3z1kAJoI0snTLMosE0G1IZZmRSLE4PcuHWNvrPWqyzdssWmDoVtm2r/Y9sYKD6BJB/1aB7DKJL2rFK2uetkhJAm1g6ZZgFxw2xM3yM1vrxGRYcF9S62yYJlOrw3bYNTj+9vm2Xqtf29Y3tA4Duu4zXWHWJiRJAm1g0mN7X+Ofs7M2yaDDdPgmgUaMqijV4peYLmjUr+L5bG8hGjVVXEpEaKAG0iQ2p4o1oqeWxaMSoilIN3nHHBV+lGrFubcwaMYxWNzxJjZQA2sSMTIr14w9sXGdk2mjIWj2zeuafoRbKZoM+gCSeuTbiqko3PEmNNAy0TSxOD3LI6NhfxyGjPSxOt1Gte2AgOEvPnfGnUsHPlRqZ3BlqpUYtd+Y6PNyYeDtBI4bR6oYnqVGsVwBmdg7wdYKpeK519/8VZzxxytX523oUEFQeVVGsFl3qTt9iclcDSbkiqPdZCeWSpW54kgpiSwBm1gt8C3gzsBF4wMx+7e5/iiumuF24daD9GvxqDA+ztG8di/4RNkyEGS9mWHzXOi6s9US0WC272zo7BwaCOY82bdq/bOrU6qbRKKWbRkpJU8RZAjoVeMLd0+6+G1gGvCPGeKROSw96jAXnwfrDwC34d8F5sPTEOjaaf9dvYSmpG0pGw8PBvRT5tmyJ/pnKlXk6OTFKS8SZAI4Ens77eWO4bAwzW2Bma8xszbN79rQsOKneorOcnQeNXbbzIFj0xjo3nGvkSnV2rlsHq1fXngiGh4P3r1xZ33ZqUa4DN4pG9CFIYsXZB2BFlh3wRBZ3XwIsAZjT31/6iS3SXJVKL8PDbJhY/K2llle9/3Jnu/WMn2/UEMpaylPlOnBXrqy8HT1vWeoQZwLYCByd9/NRwKYS60qcKjWS4eszXgzKPoVmvFhm2/kN3PBw6Skh0unS9yHk5A99jNoYN2oIZa2JpNJnqrQdzXcjdYgzATwAzDKzVwPPAPOBv48xnuTKbyz7+oJHY46Olh/Fkyu9pNPButksi+8Kav75ZaBDdsPiu4rss68vuMu3sHO3lEwGjj/+wLPdYutV0xg3aghlrYmk2Bl8oUrb0Xw3UqPYEoC77zWzjwG3EwwDvd7dH40rnq5W7my4sLHcm/fYzFzDWanBDV34h+DfRW/MjQIKGv/c8jH27t3fKEPl/aRSB57tllqvmsa4UXPG15pIonymKNsRqUGs9wG4+y3ALXHG0JXyG/ze3qDxyz3wvvBsuNIY/ajj90MX/qFEg19q27mz/nL7ya9p5852CxNX/nqlykiZTNDJm58AG1VDryeR5J/Br16th5hIy+hO4G5TOFRydHR/45+T3/DGfWaZyZSPofBu49yInXXrgoa6t3f/elOnVh49Uzh0tNa7mws16uEjeoiJtJDmAuom5TpRC+VGmbSzVGrsNNPFylU9PUHfAFQuI+UUloMaUUNvVGesOnWlhZQAukWucewW+We9lSaSi1JGKtSMK59GdcaqU1daRAmgW1Qz3067KxwaWkVHdFX7EEk4JYBOVTiyJ+5afjl9fWNHF1WSX/aJkthyjXmxY9DbG/SBROnk7bZ5hkQqUALoRMXGuberahv/QlE+W64xLzaa59hjg+8rNex6qIokkBJAO6j2zLOTyj3VNv6FpZkoVzf5x6rWJ4rpoSqSQEoAcavlzLOdz/jrUaw0M3ny2KmSC+UnjHo6T/VQFUkg3QcQt1pmg2xVB6aF8/X1Nek8Yfr0sT8XzoNfbKrkfI0cH69ZNSWBlAAabOmUYWaetpqeuSuZedpqlk6pMLVwLWeexW4Wagb3oAGcNSsYa5+76SqK/Ju0iunrqzwPfrlSV603bJWiG7AkgZQAGmjplGEWHDfE+vGZ4IEo4zMsOG6ofBKo5cxzYAAOPbS+YKPKL0lVuhIovJs21wFbyOzAkTlw4JVPuSR4+umNrc036o5gkQ6iPoAGWjSYZmfv2EZtZ2+WRYPp0o96LDUXzeTJ++eFSaWCn7dt2z+/z+hoEz9JgVzDXGnKhvzhm/kef3x/vLlZQMvN15O/zVbOi6MbsCRhlAAaaEOqeANZajlQ/Nb/yZODckh+x3B+R2grG/+cSvcblCqVlGpUSyWU/MZdDzsRaSolgAaakUmxfvyBjdqMTIUz1sJGcvXq9hvmmRtWWeyu3OnTa5s8rVLjrnlxRJpKCaCBFqcHWXDc0Jgy0CGjPSxOV3nGWs/Qw+nTyw+brEWuYW5kgxx1WyrLiDSNEkAD5er8iwbTbEhlmJFJsTg9WLr+X0o9Uzts3Vrb+3J6eoLhmLn+hmI3VDWqQVbjLhIrJYAGu3DrQPUNfqEojwkspdo7b3t7g45ZlVhEEkcJoB1FfUxgNUpNinbssWrwRRJKCaBd5ZdHokyJXE41k6KJSGIoAXSCwiuC3t7gZqpS5Z5yZR01+CISUgJoU0unDB/YmTxQcKNVqQejq6wjIhEoAbSh3JQSueGkuSklgLEdzBonLyJ1iCUBmNl7gS8CxwOnuvuaOOJoV1VNKaGhlCJSo7gmg/sj8C7gnpj239ZqmlJCRKRKsSQAd1/n7kNx7LsTlJo6ouKUEiIiVWj76aDNbIGZrTGzNc/u2RN3OC2xOD3IIaNjfzU1TSkhIlJG0/oAzOxOYGqRlxa5+6+ibsfdlwBLAOb093uDwmtrDZtSQkSkjKYlAHd/U7O2nQQNmVJCRKSMti8BiYhIc8SSAMzsfDPbCJwO3Gxmt8cRh4hIksVyH4C7LweWx7FvEREJqAQkIpJQSgAiIgmlBCAiklBKACIiCaUEICKSUEoAIiIJpQQgIpJQSgAiIgmlBCAiklBKACIiCaUEICKSUEoAIiIJpQQgIpJQSgAiIgmlBCAiklBKACIiCaUEICKSUEoAIiIJpQQgIpJQSgAiIgmlBCAiklBKACIiCaUEICKSUObucccQmZk9C6yvYxOHA881KJxmU6zN00nxKtbm6KRYof54X+XuRxQu7KgEUC8zW+Puc+KOIwrF2jydFK9ibY5OihWaF69KQCIiCaUEICKSUElLAEviDqAKirV5OilexdocnRQrNCneRPUBiIjIfkm7AhARkZASgIhIQiUuAZjZv5jZY2b2iJktN7PD4o6pFDN7r5k9amZZM2vLIWtmdo6ZDZnZE2b22XukfvAAAAPkSURBVLjjKcfMrjezrWb2x7hjKcfMjjazFWa2Lvz9fzLumMoxs/Fmdr+ZPRzGe3ncMVViZr1m9v/M7Ka4YynHzJ4ysz+Y2VozW9Po7ScuAQB3ACe4++uAx4FLY46nnD8C7wLuiTuQYsysF/gW8Bbgr4ALzOyv4o2qrO8D58QdRAR7gU+7+/HAacD/aPPjmgHmuftJwGzgHDM7LeaYKvkksC7uICI6y91n6z6ABnD337j73vDH+4Cj4oynHHdf5+5DccdRxqnAE+6edvfdwDLgHTHHVJK73wM8H3cclbj7Znd/KPx+B0FDdWS8UZXmgZHwx3HhV9uOLjGzo4C3AdfGHUvcEpcACvxX4Na4g+hgRwJP5/28kTZuqDqRmc0ETgZ+H28k5YUllbXAVuAOd2/neK8GLgGycQcSgQO/MbMHzWxBozfe1+gNtgMzuxOYWuSlRe7+q3CdRQSX2ktbGVuhKLG2MSuyrG3P/DqNmU0Afg58yt1fijuectx9FJgd9qktN7MT3L3t+lrM7Fxgq7s/aGZnxh1PBGe4+yYzmwLcYWaPhVeyDdGVCcDd31TudTP7IHAu8EaP+UaISrG2uY3A0Xk/HwVsiimWrmJm4wga/6Xu/ou444nK3V8ws5UEfS1tlwCAM4C3m9lbgfHAoWZ2g7tfFHNcRbn7pvDfrWa2nKDs2rAEkLgSkJmdA3wGeLu774w7ng73ADDLzF5tZgcB84FfxxxTxzMzA64D1rn7lXHHU4mZHZEbTWdmBwNvAh6LN6ri3P1Sdz/K3WcS/H/9bbs2/mb2CjPrz30PnE2Dk2riEgDwTaCf4HJqrZl9N+6ASjGz881sI3A6cLOZ3R53TPnCzvSPAbcTdFT+1N0fjTeq0szsx8Bq4Dgz22hmH447phLOAD4AzAv/j64Nz1jb1TRghZk9QnBScIe7t/Xwyg4xAKwys4eB+4Gb3f22Ru5AU0GIiCRUEq8AREQEJQARkcRSAhARSSglABGRhFICEBFJKCUAkSqEQ3PdzF4T/jwzN7uomU3OG7a5xcyeyfv5oHgjFzmQEoBIdS4AVhHcRDSGu28LZ22cDXwXuCr3czhZnkhbUQIQiSicm+cM4MMUSQAinUYJQCS6dwK3ufvjwPNm9tdxByRSDyUAkeguIHjmAeG/F8QYi0jdunI2UJFGM7PJwDzgBDNzoJdg6utvxxqYSB10BSASzXuAH7r7q9x9prsfDTxJGz9RTqQSJQCRaC4Alhcs+znwOfbPLpr7em/rwxOpnmYDFRFJKF0BiIgklBKAiEhCKQGIiCSUEoCISEIpAYiIJJQSgIhIQikBiIgk1P8HP9w4tTp4eYEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising the Test set results\n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_test1, y_test\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, lr.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('Logistic Regression (Test set)')\n",
    "plt.xlabel('ALT')\n",
    "plt.ylabel('AST')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходя из графика можем сделать вывод, что чем значения ALT и AST меньше, тем меньше людей подвержены заболеваию (количество \n",
    "здоровых больше). И чем значения ALT и AST, тем больше люди подвержены заболеваию (количество больных больше). Зеленые точки на \n",
    "красном фоне - ошибка модели, заболевшие люди определились как здоровые. Красных точек на зеленом фоне нет. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишем наши выборки в объект для того, чтобы использовать ее для построения все основных моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "obj = {'X_train': X_train1, 'X_test': X_test1,'y_train': y_train,'y_test': y_test}\n",
    "output = open('data.pkl', 'wb')\n",
    "pickle.dump(obj, output, 2)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14 Classification Neural Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим модель классификации, основанную на нейронных сетях. Импортируем библиотеки, данные и модули."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing prepared dataset\n",
    "import pickle\n",
    "input = open('data.pkl', 'rb')\n",
    "obj = pickle.load(input)\n",
    "input.close()\n",
    "X_train = obj[\"X_train\"]\n",
    "X_test = obj[\"X_test\"]\n",
    "y_train = obj[\"y_train\"]\n",
    "y_test = obj[\"y_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Tensorflow\n",
    "# Install Keras\n",
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим нейронную сеть прямой передачи сигнала. Обычно для этого используется сужающая архитектура -число нейронов на первом\n",
    "слое не превышает число нейронов на входном слое. Т.к. у нас всего 2 параметра классификации - на входном слое у нас будет всего\n",
    "2 нейрона. Поэтому на 1м слое мы тоже будем использовать 2 нейрона. На втором слое выберем один нейрон, т.к.  одного\n",
    "элемента со значением 0;1  будет достаточно. Число выходов классификатора= число классов -1. Используем сигмоидальную ф-ю, т.к.\n",
    "она изменяется в интервале [0;1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the ANN\n",
    "cnn = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "cnn.add(Dense(units = 2, kernel_initializer = 'uniform', activation = 'relu', input_dim = 2))\n",
    "\n",
    "# Adding the output layer\n",
    "cnn.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим нашу нейронную сеть в течении 100 эпох и посмотрим, каков прогноз и качество прогноза на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 1/50 [..............................] - ETA: 0s - loss: 0.6931 - accuracy: 0.6000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "50/50 [==============================] - 0s 600us/step - loss: 0.6838 - accuracy: 0.8577\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 0s 520us/step - loss: 0.6625 - accuracy: 0.8638\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 0s 440us/step - loss: 0.6362 - accuracy: 0.8638\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 0s 500us/step - loss: 0.6056 - accuracy: 0.8638\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 0s 420us/step - loss: 0.5711 - accuracy: 0.8638\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 0s 520us/step - loss: 0.5349 - accuracy: 0.8760\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 0s 440us/step - loss: 0.4984 - accuracy: 0.9045\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 0s 460us/step - loss: 0.4623 - accuracy: 0.9106\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 0s 440us/step - loss: 0.4280 - accuracy: 0.9187\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 0s 460us/step - loss: 0.3957 - accuracy: 0.9207\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 0s 500us/step - loss: 0.3662 - accuracy: 0.9268\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 0s 460us/step - loss: 0.3398 - accuracy: 0.9289\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 0s 460us/step - loss: 0.3164 - accuracy: 0.9329\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 0s 420us/step - loss: 0.2954 - accuracy: 0.9350\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 0s 460us/step - loss: 0.2776 - accuracy: 0.9390\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 0s 400us/step - loss: 0.2620 - accuracy: 0.9390\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 0s 460us/step - loss: 0.2484 - accuracy: 0.9370\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 0s 420us/step - loss: 0.2364 - accuracy: 0.9370\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 0s 480us/step - loss: 0.2262 - accuracy: 0.9370\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 0s 500us/step - loss: 0.2174 - accuracy: 0.9370\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 0s 900us/step - loss: 0.2098 - accuracy: 0.9370\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 0s 500us/step - loss: 0.2035 - accuracy: 0.9370\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 0s 500us/step - loss: 0.1985 - accuracy: 0.9370\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 0s 700us/step - loss: 0.1939 - accuracy: 0.9350\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 0s 460us/step - loss: 0.1899 - accuracy: 0.9370\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 0s 420us/step - loss: 0.1867 - accuracy: 0.9370\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 0s 500us/step - loss: 0.1838 - accuracy: 0.9370\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 0s 480us/step - loss: 0.1811 - accuracy: 0.9370\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 0s 440us/step - loss: 0.1790 - accuracy: 0.9370\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - 0s 500us/step - loss: 0.1772 - accuracy: 0.9370\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 0s 500us/step - loss: 0.1755 - accuracy: 0.9370\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 0s 500us/step - loss: 0.1738 - accuracy: 0.9370\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 0s 500us/step - loss: 0.1725 - accuracy: 0.9390\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 0s 480us/step - loss: 0.1713 - accuracy: 0.9390\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 0s 480us/step - loss: 0.1702 - accuracy: 0.9390\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 0s 500us/step - loss: 0.1693 - accuracy: 0.9390\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 0s 440us/step - loss: 0.1683 - accuracy: 0.9370\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 0s 500us/step - loss: 0.1676 - accuracy: 0.9370\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 0s 480us/step - loss: 0.1669 - accuracy: 0.9370\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 0s 500us/step - loss: 0.1663 - accuracy: 0.9370\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 0s 500us/step - loss: 0.1660 - accuracy: 0.9370\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 0s 460us/step - loss: 0.1654 - accuracy: 0.9370\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 0s 460us/step - loss: 0.1649 - accuracy: 0.9370\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - 0s 440us/step - loss: 0.1644 - accuracy: 0.9390\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 0s 440us/step - loss: 0.1639 - accuracy: 0.9390\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 0s 400us/step - loss: 0.1636 - accuracy: 0.9411\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 0s 440us/step - loss: 0.1630 - accuracy: 0.9411\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 0s 400us/step - loss: 0.1626 - accuracy: 0.9411\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 0s 760us/step - loss: 0.1623 - accuracy: 0.9411\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 0s 480us/step - loss: 0.1620 - accuracy: 0.9411\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 0s 440us/step - loss: 0.1615 - accuracy: 0.9411\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 0s 500us/step - loss: 0.1614 - accuracy: 0.9411\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 0s 480us/step - loss: 0.1609 - accuracy: 0.9411\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 0s 460us/step - loss: 0.1606 - accuracy: 0.9411\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 0s 440us/step - loss: 0.1604 - accuracy: 0.9411\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 0s 500us/step - loss: 0.1601 - accuracy: 0.9411\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 0s 580us/step - loss: 0.1599 - accuracy: 0.9411\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 0s 540us/step - loss: 0.1595 - accuracy: 0.9411\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 0s 440us/step - loss: 0.1595 - accuracy: 0.9411\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 0s 480us/step - loss: 0.1591 - accuracy: 0.9411\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 0s 440us/step - loss: 0.1589 - accuracy: 0.9411\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 0s 480us/step - loss: 0.1588 - accuracy: 0.9411\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 0s 440us/step - loss: 0.1586 - accuracy: 0.9411\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 0s 480us/step - loss: 0.1585 - accuracy: 0.9431\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 0s 500us/step - loss: 0.1582 - accuracy: 0.9411\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 0s 440us/step - loss: 0.1581 - accuracy: 0.9411\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 0s 460us/step - loss: 0.1581 - accuracy: 0.9411\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - 0s 460us/step - loss: 0.1578 - accuracy: 0.9411\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 0s 460us/step - loss: 0.1578 - accuracy: 0.9411\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 0s 460us/step - loss: 0.1576 - accuracy: 0.9411\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 0s 460us/step - loss: 0.1576 - accuracy: 0.9411\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 0s 460us/step - loss: 0.1574 - accuracy: 0.9411\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 0s 460us/step - loss: 0.1573 - accuracy: 0.9390\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 0s 480us/step - loss: 0.1570 - accuracy: 0.9390\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 0s 440us/step - loss: 0.1566 - accuracy: 0.9390\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 0s 460us/step - loss: 0.1565 - accuracy: 0.9411\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 0s 440us/step - loss: 0.1563 - accuracy: 0.9411\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 440us/step - loss: 0.1561 - accuracy: 0.9431\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 0s 420us/step - loss: 0.1558 - accuracy: 0.9431\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 0s 500us/step - loss: 0.1558 - accuracy: 0.9431\n",
      "Epoch 81/100\n",
      "50/50 [==============================] - 0s 420us/step - loss: 0.1556 - accuracy: 0.9431\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 0s 440us/step - loss: 0.1556 - accuracy: 0.9431\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 0s 440us/step - loss: 0.1554 - accuracy: 0.9431\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 0s 440us/step - loss: 0.1554 - accuracy: 0.9411\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 0s 480us/step - loss: 0.1553 - accuracy: 0.9431\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 0s 440us/step - loss: 0.1551 - accuracy: 0.9411\n",
      "Epoch 87/100\n",
      "50/50 [==============================] - 0s 460us/step - loss: 0.1551 - accuracy: 0.9411\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 0s 440us/step - loss: 0.1549 - accuracy: 0.9390\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 0s 460us/step - loss: 0.1548 - accuracy: 0.9390\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 0s 440us/step - loss: 0.1546 - accuracy: 0.9390\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 0s 460us/step - loss: 0.1547 - accuracy: 0.9390\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - 0s 420us/step - loss: 0.1546 - accuracy: 0.9390\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - 0s 480us/step - loss: 0.1544 - accuracy: 0.9390\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - 0s 440us/step - loss: 0.1544 - accuracy: 0.9411\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - 0s 620us/step - loss: 0.1543 - accuracy: 0.9390\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - 0s 440us/step - loss: 0.1541 - accuracy: 0.9390\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - 0s 440us/step - loss: 0.1542 - accuracy: 0.9390\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - 0s 460us/step - loss: 0.1541 - accuracy: 0.9390\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - 0s 440us/step - loss: 0.1540 - accuracy: 0.9390\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - 0s 460us/step - loss: 0.1537 - accuracy: 0.9390\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1df2c785640>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "cnn.fit(X_train, y_train, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем прогнозирование "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = cnn.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Построим таблицу сопряженности. Видим, что 4 положительных случаев ложно определены как отрицательные и 1 отрицательный\n",
    "случаей ложно определен как положительный. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107   1]\n",
      " [  4  11]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Посмотрим на разделяющую кривая. Она нелинейна. 5 объектов определены ошибочно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2-D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2-D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising the Test set results\n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_test, y_test\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, cnn.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('NN (Test set)')\n",
    "plt.xlabel('ALT')\n",
    "plt.ylabel('AST')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Увеличим число нейронов на первом слое до 8ми. Получим:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the ANN\n",
    "cnn = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "cnn.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu', input_dim = 2))\n",
    "\n",
    "# Adding the output layer\n",
    "cnn.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим нашу нейронную сеть в течении 100 эпох и посмотрим, каков прогноз и качество прогноза на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50/50 [==============================] - 0s 880us/step - loss: 0.6830 - accuracy: 0.8394\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 0s 960us/step - loss: 0.6547 - accuracy: 0.8862\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 0s 960us/step - loss: 0.6084 - accuracy: 0.9045\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 0s 960us/step - loss: 0.5397 - accuracy: 0.9187\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.4632 - accuracy: 0.9329\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 0s 960us/step - loss: 0.3920 - accuracy: 0.9370\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 0s 960us/step - loss: 0.3335 - accuracy: 0.9370\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.2888 - accuracy: 0.9370\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 0s 960us/step - loss: 0.2554 - accuracy: 0.9350\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.2311 - accuracy: 0.9350\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 0s 960us/step - loss: 0.2132 - accuracy: 0.9350\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 0s 960us/step - loss: 0.2006 - accuracy: 0.9370\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 0s 960us/step - loss: 0.1908 - accuracy: 0.9350\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 0s 880us/step - loss: 0.1841 - accuracy: 0.9390\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1789 - accuracy: 0.9390\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 0s 902us/step - loss: 0.1751 - accuracy: 0.9370\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1721 - accuracy: 0.9350\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 0s 880us/step - loss: 0.1693 - accuracy: 0.9370\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1672 - accuracy: 0.9390\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 0s 880us/step - loss: 0.1659 - accuracy: 0.9411\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 0s 960us/step - loss: 0.1643 - accuracy: 0.9411\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 0s 960us/step - loss: 0.1634 - accuracy: 0.9411\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 0s 960us/step - loss: 0.1621 - accuracy: 0.9411\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 0s 960us/step - loss: 0.1614 - accuracy: 0.9411\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 0s 960us/step - loss: 0.1608 - accuracy: 0.9411\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 0s 960us/step - loss: 0.1602 - accuracy: 0.9411\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 0s 960us/step - loss: 0.1595 - accuracy: 0.9411\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 0s 931us/step - loss: 0.1589 - accuracy: 0.9411\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 0s 960us/step - loss: 0.1587 - accuracy: 0.9411\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - 0s 902us/step - loss: 0.1580 - accuracy: 0.9411\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1567 - accuracy: 0.9411\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1561 - accuracy: 0.9411\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 0s 880us/step - loss: 0.1559 - accuracy: 0.9411\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 0s 880us/step - loss: 0.1546 - accuracy: 0.9431\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1541 - accuracy: 0.9411\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 0s 880us/step - loss: 0.1536 - accuracy: 0.9431\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 0s 830us/step - loss: 0.1527 - accuracy: 0.9431\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1522 - accuracy: 0.9411\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1517 - accuracy: 0.9411\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 0s 741us/step - loss: 0.1507 - accuracy: 0.9431\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 0s 753us/step - loss: 0.1502 - accuracy: 0.9431\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 0s 720us/step - loss: 0.1498 - accuracy: 0.9390\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1493 - accuracy: 0.9390\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - 0s 720us/step - loss: 0.1491 - accuracy: 0.9390\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1484 - accuracy: 0.9390\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 0s 705us/step - loss: 0.1482 - accuracy: 0.9390\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1475 - accuracy: 0.9411\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 0s 720us/step - loss: 0.1472 - accuracy: 0.9370\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 0s 790us/step - loss: 0.1467 - accuracy: 0.9370\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1464 - accuracy: 0.9411\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 0s 742us/step - loss: 0.1459 - accuracy: 0.9390\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 0s 720us/step - loss: 0.1459 - accuracy: 0.9431\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 0s 640us/step - loss: 0.1455 - accuracy: 0.9431\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1450 - accuracy: 0.9431\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1446 - accuracy: 0.9431\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 0s 640us/step - loss: 0.1443 - accuracy: 0.9431\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 0s 721us/step - loss: 0.1441 - accuracy: 0.9431\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 0s 720us/step - loss: 0.1439 - accuracy: 0.9431\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1434 - accuracy: 0.9431\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 0s 822us/step - loss: 0.1427 - accuracy: 0.9431\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1427 - accuracy: 0.9431\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 0s 705us/step - loss: 0.1419 - accuracy: 0.9431\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1416 - accuracy: 0.9451\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 0s 720us/step - loss: 0.1414 - accuracy: 0.9431\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 0s 661us/step - loss: 0.1410 - accuracy: 0.9472\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 0s 720us/step - loss: 0.1405 - accuracy: 0.9472\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 0s 640us/step - loss: 0.1401 - accuracy: 0.9512\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0285 - accuracy: 1.00 - 0s 640us/step - loss: 0.1397 - accuracy: 0.9512\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 0s 720us/step - loss: 0.1391 - accuracy: 0.9512\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 0s 720us/step - loss: 0.1390 - accuracy: 0.9492\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1383 - accuracy: 0.9512\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 0s 640us/step - loss: 0.1380 - accuracy: 0.9512\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 0s 640us/step - loss: 0.1376 - accuracy: 0.9512\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 0s 640us/step - loss: 0.1374 - accuracy: 0.9492\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 0s 675us/step - loss: 0.1371 - accuracy: 0.9512\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 0s 720us/step - loss: 0.1368 - accuracy: 0.9512\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 0s 720us/step - loss: 0.1363 - accuracy: 0.9512\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 0s 720us/step - loss: 0.1360 - accuracy: 0.9512\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 0s 640us/step - loss: 0.1358 - accuracy: 0.9492\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 0s 720us/step - loss: 0.1354 - accuracy: 0.9512\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 741us/step - loss: 0.1351 - accuracy: 0.9512\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 0s 720us/step - loss: 0.1348 - accuracy: 0.9512\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 0s 720us/step - loss: 0.1345 - accuracy: 0.9512\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 0s 729us/step - loss: 0.1344 - accuracy: 0.9512\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1339 - accuracy: 0.9533\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1336 - accuracy: 0.9533\n",
      "Epoch 87/100\n",
      "50/50 [==============================] - 0s 831us/step - loss: 0.1333 - accuracy: 0.9533\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1331 - accuracy: 0.9533\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 0s 720us/step - loss: 0.1328 - accuracy: 0.9533\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 0s 720us/step - loss: 0.1325 - accuracy: 0.9512\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 0s 640us/step - loss: 0.1322 - accuracy: 0.9512\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - 0s 720us/step - loss: 0.1321 - accuracy: 0.9512\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - 0s 640us/step - loss: 0.1319 - accuracy: 0.9512\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - 0s 560us/step - loss: 0.1313 - accuracy: 0.9512\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - 0s 640us/step - loss: 0.1312 - accuracy: 0.9533\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - 0s 640us/step - loss: 0.1313 - accuracy: 0.9512\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - 0s 679us/step - loss: 0.1309 - accuracy: 0.9512\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - 0s 640us/step - loss: 0.1305 - accuracy: 0.9512\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - 0s 560us/step - loss: 0.1304 - accuracy: 0.9512\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - 0s 560us/step - loss: 0.1303 - accuracy: 0.9512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1df25457a30>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "cnn.fit(X_train, y_train, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем прогнозирование "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = cnn.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим таблицу сопряженности. Видим, что 3 положительных случаев ложно определены как отрицательные и 1 отрицательный\n",
    "случаей ложно определен как положительный. Как видим, усложнение конфигурации сети в данном случае привело к незначительному\n",
    "улучшению модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107   1]\n",
      " [  3  12]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как изменилась наша разделяющая кривая. Она нелинейна. Ее степень немного выше, наблюдаем небольшое улучшение\n",
    "результата."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2-D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2-D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising the Test set results\n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_test, y_test\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, cnn.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('NN (Test set)')\n",
    "plt.xlabel('ALT')\n",
    "plt.ylabel('AST')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Увеличим число нейронов на первом слое до 16ми. Получим:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the ANN\n",
    "cnn = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "cnn.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu', input_dim = 2))\n",
    "\n",
    "# Adding the output layer\n",
    "cnn.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим нашу нейронную сеть в течении 100 эпох и посмотрим, каков прогноз и качество прогноза на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.6776 - accuracy: 0.8801\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.6251 - accuracy: 0.9065\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.5373 - accuracy: 0.9248\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.4344 - accuracy: 0.9350\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.3424 - accuracy: 0.9370\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.2769 - accuracy: 0.9350\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.2342 - accuracy: 0.9350\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.2085 - accuracy: 0.9350\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1917 - accuracy: 0.9350\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 0s 880us/step - loss: 0.1816 - accuracy: 0.9370\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1747 - accuracy: 0.9370\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 0s 960us/step - loss: 0.1703 - accuracy: 0.9370\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 0s 960us/step - loss: 0.1667 - accuracy: 0.9370\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 0s 960us/step - loss: 0.1645 - accuracy: 0.9411\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 0s 960us/step - loss: 0.1620 - accuracy: 0.9411\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 0s 960us/step - loss: 0.1603 - accuracy: 0.9411\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 0s 960us/step - loss: 0.1590 - accuracy: 0.9411\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 0s 960us/step - loss: 0.1577 - accuracy: 0.9411\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 0s 963us/step - loss: 0.1568 - accuracy: 0.9431\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 0s 917us/step - loss: 0.1561 - accuracy: 0.9431\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1551 - accuracy: 0.9431\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1547 - accuracy: 0.9411\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 0s 960us/step - loss: 0.1540 - accuracy: 0.9431\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 0s 960us/step - loss: 0.1531 - accuracy: 0.9451\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 0s 960us/step - loss: 0.1523 - accuracy: 0.9431\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1519 - accuracy: 0.9411\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1513 - accuracy: 0.9390\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 0s 880us/step - loss: 0.1507 - accuracy: 0.9390\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1501 - accuracy: 0.9390\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1491 - accuracy: 0.9390\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 0s 960us/step - loss: 0.1490 - accuracy: 0.9370\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 0s 880us/step - loss: 0.1481 - accuracy: 0.9370\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 0s 960us/step - loss: 0.1476 - accuracy: 0.9370\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 0s 960us/step - loss: 0.1471 - accuracy: 0.9370\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 0s 960us/step - loss: 0.1466 - accuracy: 0.9370\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1465 - accuracy: 0.9370\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 0s 880us/step - loss: 0.1457 - accuracy: 0.9390\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 0s 880us/step - loss: 0.1451 - accuracy: 0.9390\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 0s 880us/step - loss: 0.1447 - accuracy: 0.9390\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 0s 880us/step - loss: 0.1440 - accuracy: 0.9390\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 0s 880us/step - loss: 0.1439 - accuracy: 0.9431\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1433 - accuracy: 0.9411\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 0s 880us/step - loss: 0.1428 - accuracy: 0.9390\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1430 - accuracy: 0.9390\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1420 - accuracy: 0.9411\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1417 - accuracy: 0.9411\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 0s 880us/step - loss: 0.1412 - accuracy: 0.9390\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 0s 828us/step - loss: 0.1410 - accuracy: 0.9431\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1408 - accuracy: 0.9411\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 0s 743us/step - loss: 0.1402 - accuracy: 0.9451\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1399 - accuracy: 0.9390\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1397 - accuracy: 0.9411\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1390 - accuracy: 0.9451\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 0s 720us/step - loss: 0.1387 - accuracy: 0.9431\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 0s 902us/step - loss: 0.1384 - accuracy: 0.9451\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 0s 880us/step - loss: 0.1382 - accuracy: 0.9431\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1381 - accuracy: 0.9431\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1373 - accuracy: 0.9472\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1371 - accuracy: 0.9451\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1367 - accuracy: 0.9472\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1365 - accuracy: 0.9492\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1360 - accuracy: 0.9492\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1360 - accuracy: 0.9492\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1356 - accuracy: 0.9472\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1352 - accuracy: 0.9492\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1348 - accuracy: 0.9472\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1346 - accuracy: 0.9492\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1342 - accuracy: 0.9492\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 0s 880us/step - loss: 0.1340 - accuracy: 0.9492\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1337 - accuracy: 0.9492\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1337 - accuracy: 0.9492\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1335 - accuracy: 0.9492\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 0s 880us/step - loss: 0.1329 - accuracy: 0.9492\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1326 - accuracy: 0.9512\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 0s 880us/step - loss: 0.1328 - accuracy: 0.9512\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1327 - accuracy: 0.9512\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1320 - accuracy: 0.9492\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 0s 827us/step - loss: 0.1316 - accuracy: 0.9533\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1313 - accuracy: 0.9512\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 0s 742us/step - loss: 0.1310 - accuracy: 0.9512\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 880us/step - loss: 0.1308 - accuracy: 0.9512\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1309 - accuracy: 0.9512\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 0s 960us/step - loss: 0.1309 - accuracy: 0.9533\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1302 - accuracy: 0.9512\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 0s 880us/step - loss: 0.1300 - accuracy: 0.9512\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1296 - accuracy: 0.9533\n",
      "Epoch 87/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1293 - accuracy: 0.9533\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 0s 880us/step - loss: 0.1291 - accuracy: 0.9533\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 0s 880us/step - loss: 0.1292 - accuracy: 0.9533\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1286 - accuracy: 0.9512\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 0s 880us/step - loss: 0.1287 - accuracy: 0.9512\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - 0s 842us/step - loss: 0.1289 - accuracy: 0.9512\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1281 - accuracy: 0.9533\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1282 - accuracy: 0.9533\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - 0s 822us/step - loss: 0.1281 - accuracy: 0.9533\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - 0s 960us/step - loss: 0.1279 - accuracy: 0.9533\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - 0s 879us/step - loss: 0.1278 - accuracy: 0.9533\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1277 - accuracy: 0.9533\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1274 - accuracy: 0.9533\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.1275 - accuracy: 0.9553\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1df2e998430>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "cnn.fit(X_train, y_train, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем прогнозирование "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = cnn.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим таблицу сопряженности. Видим, что 3 положительных случаев ложно определены как отрицательные и 1 отрицательный\n",
    "случаей ложно определен как положительный. Как видим, усложнение конфигурации сети в данном случае не привело улучшению модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107   1]\n",
      " [  3  12]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как изменрилась наша разделяющая кривая. Она нелинейна. Ее степень немного выше, улучшение\n",
    "результата не наблюдаем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2-D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2-D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising the Test set results\n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_test, y_test\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, cnn.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('NN (Test set)')\n",
    "plt.xlabel('ALT')\n",
    "plt.ylabel('AST')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВЫВОД\n",
    "Исходя из всего вышеприведенного, можем сделать вывод, что в данном случае усложнение модели не приведет к значительным сдвигам\n",
    "результата в положительную сторону. Можно сказать, что скорее всего мы достигли максимального качества данной модели. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
